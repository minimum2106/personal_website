<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="description" content="minimum2106's online CV">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="minimum2106">
    <!-- Updated Font Awesome to latest version for better icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <main>
        <div class="nav">
            <ul>
                <li><a class="active" href="#aboutMe">About <span style="color: red;">Quan!</span></a></li>
                <li><a href="#project">Projects</a></li>
                <li><a href="#education">Education</a></li>
                <li><a href="#experience">Experience</a></li>
            </ul>
        </div>
        <section id="aboutMe" class="summaryWrapper">
            <div class="avatarWrapper"><img src="assets/avatar.jpg"></div>
            <div class="summaryDescription">
                <p>
                    Hi, I'm <span class="bolded">Hong Quan Tran</span>! I graduated from Université Paris Cité and have
                    two years of apprenticeship
                    experience tackling various Machine Learning challenges and developing ML-driven products.
                    I'm passionate about problem-solving and exploring how AI can be applied to real-world scenarios.
                    In my last year as a Data Science apprentice, I focused on modern NLP techniques, including
                    fine-tuning large pre-trained models, Retrieval-Augmented Generation (RAG), and Agentic AI,
                    integrating them into real use cases for my company and its clients.
                    However, I'm also eager to dive into other AI domains, such as Computer Vision!
                </p>
                <p>
                    <span style="color: red;">I'm currently open to new opportunities! </span>
                    If you have a role where I can learn and grow, feel free to reach out through
                    one of my social accounts below.
                </p>
                <div class="summaryContacts">
                    <!-- Updated Font Awesome classes to v6 syntax -->
                    <div><i class="fab fa-github"></i> <a
                            href="https://github.com/minimum2106">https://github.com/minimum2106</a></div>
                    <div><i class="fas fa-envelope"></i> tranhongquan2106@gmail.com</div>
                    <div><i class="fab fa-linkedin" aria-hidden="true"></i> <a
                            href="https://www.linkedin.com/in/hong-quan-tran-363264280">www.linkedin.com/in/hong-quan-tran-363264280</a>
                    </div>
                    <div><i class="fas fa-phone"></i> +33 7 49 38 16 51</div>
                    <div><i class="fas fa-download"></i> <a href="assets/personal_cv.pdf"
                            download="Hong_Quan_Tran_CV.pdf">Download my CV</a></div>
                </div>
            </div>
        </section>
        <!-- ################################ Experiences ################################ -->
        <section id="experience" class="infoSection">
            <h1>Work Experiences</h1>
            <ul>
                <li>
                    <div class="periodHeader">
                        <h3>Machine Learning Engineer Apprentice</h3>
                        <span>Oct 2022 - Sep 2024</span>
                    </div>
                    <h5 class="periodLoc">HephIA -- Paris, France</h5>
                    <div class="periodDescription">
                        <p><strong>AI Legal Assistant & NLP:</strong></p>
                        <ul>
                            <li>Fine-tuned and deployed <strong>transformer-based NLP models</strong> using
                                <strong>Transformers</strong> framework to extract <strong>legal entities</strong> and
                                <strong>anonymize sensitive data</strong>, achieving a <strong>true positive rate of
                                    over 90%</strong>.</li>
                            <li>Designed and implemented <strong>AI agent systems</strong> with
                                <strong>LangChain</strong>, <strong>LangGraph</strong> to <strong>automate legal
                                    tasks</strong>, reducing task time by <strong>20%</strong> and boosting
                                <strong>productivity</strong>.</li>
                            <li>Built and deployed <strong>RAG pipelines</strong> with <strong>LangChain</strong> and
                                <strong>vector databases</strong> (<strong>FAISS</strong>, <strong>ChromaDB</strong>,
                                <strong>MongoDB</strong>), collaborating with <strong>cross-functional teams</strong> to
                                deliver <strong>robust, customized internal search solutions</strong>.</li>
                            <li>Implemented <strong>MLOps pipelines</strong> with <strong>MLflow</strong>,
                                <strong>AWS</strong>, and <strong>Docker</strong> to <strong>monitor, evaluate</strong>,
                                and ensure <strong>reproducibility</strong> and <strong>data integrity</strong> across
                                <strong>model experiments</strong> and <strong>deployments</strong>.</li>
                        </ul>

                        <p><strong>Unsupervised Learning Platform:</strong></p>
                        <ul>
                            <li>Integrated <strong>unsupervised learning modules</strong> into the <strong>production
                                    codebase</strong> using <strong>Python</strong>, <strong>Scala</strong>, and
                                <strong>Spark</strong></li>
                            <li>Analyzed <strong>client's datasets</strong> with <strong>Scikit-learn</strong> and
                                <strong>Pandas</strong> to identify <strong>outliers</strong> and <strong>data
                                    patterns</strong></li>
                            <li>Contributed to <strong>testing cycles</strong> and <strong>CI/CD workflows</strong>,
                                maintaining clear <strong>Sphinx documentation</strong> and providing <strong>peer
                                    feedback</strong> to improve <strong>code quality</strong> and <strong>user
                                    experience</strong>.</li>
                        </ul>
                    </div>
                </li>
                <li>
                    <div class="periodHeader">
                        <h3>Data Scientist Intern</h3>
                        <span>Mar 2022 - Sep 2022</span>
                    </div>
                    <h5 class="periodLoc">HephIA -- Paris, France</h5>
                    <div class="periodDescription">
                        <ul>
                            <li>Designed <strong>custom visualizations</strong> of <strong>airplane engine data</strong>
                                using <strong>Self-Organizing Maps (SOM)</strong> with <strong>Bokeh</strong>,
                                <strong>Matplotlib</strong>, and <strong>Seaborn</strong> to reveal hidden
                                <strong>patterns</strong> in <strong>performance metrics</strong>.</li>
                            <li>Integrated these <strong>visualizations</strong> into <strong>HephIA's analytical
                                    product</strong> with <strong>PySpark</strong> and <strong>Python</strong>.</li>
                        </ul>
                    </div>
                </li>
            </ul>
        </section>
        <!-- ################################ Education ################################ -->
        <section id="education" class="infoSection">
            <h1>Education</h1>
            <ul>
                <li>
                    <div class="periodHeader">
                        <h3 class="bolded">Machine Learning pour la Science des Données (MLSD) </h3>
                        <span> Oct 2022 - Sep 2024 </span>
                    </div>
                    <h5 class="periodLoc bolded"><span>Université Paris Cité | Master</span></h5>
                    <p>
                        <strong>Courses</strong>: Big Data (Hadoop MapReduce, Apache Cassandra, Spark), Deep Learning,
                        NLP, Computer Vision, Time Series,
                        Unsupervised Learning, Reinforcement Learning, ...
                    </p>
                </li>
                <li>
                    <div class="periodHeader">
                        <h3 class="bolded"> Information and Communication Technology | Bachelor </h3>
                        <span> Oct 2019 - Sep 2022 </span>
                    </div>
                    <h5 class="periodLoc bolded"><span>University of Science and Technology of Hanoi</span></h5>
                    <div class="periodDescription">
                        <p>
                            <strong>Courses</strong>: : Databases, Distributed Computing, Algorithms and Data
                            Structures, Deep Learning, Machine Learning, Programming,
                            Probability and Statistics, Linear Algebra, ...
                        </p>
                        <ul>
                            <li><strong>Ranked top 3 of my batch</strong></li>
                            <li><strong>Erasmus+ Scholarship</strong> for an exchange program 2021-2022.</li>
                            <li><strong>USTH Scholarship regulations for students of the academic year</strong>
                                (2021-2022, 2020-2021, 2019-2020).</li>
                        </ul>
                    </div>
                </li>
            </ul>
        </section>

        <!-- ################################ Projects ################################ -->
        <section id="project" class="projectWrapper">
            <h1>Projects</h1>
            <hr>

            <!-- ################################ Easyform ################################ -->
            <div class="project">
                <div><img src="assets/projects/easyform.png"></div>
                <div class="projectDescription">
                    <a href="https://lablab.ai/event/raise-your-hack/crepegrec-qualcomm-track/easyform"
                        target="_blank">Easyform <i class="fas fa-external-link-alt"></i></a>
                    <p>
                        Our hackathon track, organized by Qualcomm and RAISE Summit, challenged participants to build
                        innovative edge AI solutions.
                        We built Easyform, a privacy-first local app that auto-fills forms using a quantized LLaMA model
                        running offline on a Snapdragon X Elite NPU of Qualcomm,
                        and leveraged Groq for ultra-fast online inference when needed.

                    <ul>
                        <li><strong> Won third place in our track </strong> for this practical and secure Edge AI
                            solution.</li>
                        <li>Currently <strong> working alongside Qualcomm </strong> to enhance the app's capabilities
                            and <strong> upload to Windows's App Store.</strong></li>
                        <li>Tech used: Tesseract OCR, EasyOCR, PyMuPDF, OpenCV, ....</li>
                    </ul>
                    </p>
                </div>
            </div>
            <hr>


            <!-- ################################ CV Comparator ################################ -->
            <div class="project">
                <div><img src="assets/projects/cv-comparator.png"></div>
                <div class="projectDescription">
                    <a href="https://github.com/minimum2106/cv-comparator" target="_blank">CV Comparator <i
                            class="fas fa-external-link-alt"></i></a>
                    <p>
                        Developed an <strong>AI-powered Orchestrator agent</strong> that dynamically generates workflows
                        based on user
                        queries to solve <strong>complex tasks</strong>.
                    <ul>
                        <li><strong>Validates user input</strong> and ensures sufficient context for task execution.
                        </li>
                        <li>Creates <strong>detailed, step-by-step execution plans</strong>.</li>
                        <li>Dynamically selects and invokes tools from a <strong>Tool Store</strong> based on task
                            requirements.</li>
                        <li>Incorporates results from dependent steps into prompts for <strong>seamless
                                execution</strong>.</li>
                        <li>Handles <strong>failure recovery</strong> with replanning and retry mechanisms.</li>
                    </ul>
                    Supports <strong>multilingual CV analysis</strong>, <strong>few-shot learning</strong>, and
                    <strong>dynamic tool integration</strong> to deliver
                    high-quality, actionable results.
                    </p>
                </div>
            </div>
            <hr>

            <!-- ################################ CV Analyzer ################################ -->
            <div class="project">
                <div>
                    <a href="https://www.youtube.com/watch?v=G0HomjKGD2Y" target="_blank">
                        <img src="assets/projects/cv-analyzer.png">
                    </a>
                </div>
                <div class="projectDescription">
                    <a href="https://github.com/minimum2106/cv-analyzer" target="_blank">CV Analyzer <i
                            class="fas fa-external-link-alt"></i></a>
                    <p>
                        <strong>Developed</strong> a <strong>Streamlit-based web application</strong> called CV
                        Analyzer, enabling users to upload their CVs and job descriptions for <strong>AI-powered
                            analysis</strong>. The application provides an intuitive interface for document upload
                        and comparison.
                    </p>
                    <ul>
                        <li> <strong>Implemented</strong> <strong>machine learning models and PyMuPDF</strong> to
                            <strong>extract
                                key information</strong> from both CVs and job descriptions. The system parses
                            documents, identifies relevant lines, and structures the extracted data for further
                            analysis.
                        </li>
                        <li> <strong>Generated job requirements</strong> and <strong>computed similarity
                                matrices</strong> by transforming text into vector embeddings. Utilized <strong>dot
                                product of embeddings</strong> to quantitatively match each CV line with job
                            requirements, ensuring accurate and explainable similarity scoring. </li>
                        <li> <strong>Leveraged LLMs</strong> (such as <strong>OpenAI</strong>, <strong>Claude</strong>,
                            and <strong>Groq</strong>) to provide <strong>detailed explanations</strong> for each match,
                            enhancing transparency and user understanding of the results. </li>
                        <li> <strong>Designed interactive visualizations</strong> to highlight matched lines and present
                            explanations, making the analysis results accessible and actionable for users. </li>
                        <li> <strong>Modular architecture</strong> with separate <strong>backend</strong> and
                            <strong>frontend</strong> components, built in <strong>Python</strong>, allowing for easy
                            local deployment and future extensibility.
                        </li>
                    </ul>
                    </p>
                </div>
            </div>
            <hr>

            <!-- ################################ FPT-Data-Centric ################################ -->
            <div class="project">
                <div><img src="assets/projects/transfer.png"></div>
                <div class="projectDescription">
                    <a href="https://github.com/minimum2106/FPT-Data-Centric" target="_blank">FPT-Data-Centric <i
                            class="fas fa-external-link-alt"></i></a>
                    <p>
                        Developed a data augmentation and preprocessing pipeline for a <strong>COVID-19
                            face mask detection competition</strong>, improving model performance by generating
                        <strong>high-quality, balanced datasets</strong> for object detection. The project
                        focused on optimizing <strong>YOLOv5s training</strong> without modifying the base model.
                    </p>
                    <ul>
                        <li>
                            Implemented <strong>Training Dynamics</strong> to identify <strong>hard-to-learn and
                                ambiguous instances</strong>, and built <strong>data augmentation and transfer
                                pipelines</strong> to enhance dataset quality and handle <strong>class
                                imbalance</strong>.
                        </li>
                        <li>Developed a <strong>reproducible pipeline</strong> for <strong>dataset preparation,
                                training, evaluation, and inference</strong>, enabling easy application of improvements.
                        </li>
                        <li>
                            Performed <strong>manual relabeling</strong> of high-confidence images to improve
                            <strong>label accuracy</strong> and reduce <strong>undetected or mismatched faces</strong>.
                        </li>
                        <li>
                            Evaluated performance using <strong>wAP@0.5</strong>, achieving improvements across
                            <strong>mask, no-mask, and incorrectly worn mask classes</strong> without modifying the base
                            model.
                        </li>
                    </ul>
                </div>
            </div>
            <hr>

            <!-- ################################ ClusterLLM ################################ -->
            <div class="project">
                <div><img src="assets/projects/clusterLLM.jpg"></div>
                <div class="projectDescription">
                    <a href="https://github.com/minimum2106/ClusterLLM" target="_blank">ClusterLLM <i
                            class="fas fa-external-link-alt"></i></a>
                    <p>
                        As part of my master's program, I built upon the original work of the <a
                            href="https://arxiv.org/abs/2305.14871"
                            style="font-style: italic; font-size: inherit;">ClusterLLM</a>
                        paper, which investigates how Large Language Models (LLMs) can improve unsupervised learning by
                        refining textual embeddings with an LLM-based
                        evaluator. In this project, I enhanced the authors' approach by developing a custom loss
                        function to replace the
                        original one and fine-tuning hyperparameters to optimize the pipeline.
                    </p>
                </div>
            </div>
            <hr>

            <!-- ################################ Unsupervised Project 1 ################################ -->
            <div class="project">
                <div><img src="assets/projects/ul1.png"></div>
                <div class="projectDescription">
                    <h4><a href="https://drive.google.com/file/d/15azky4HOWc4dTUCLFo6ABjsAtPKvLHLP/view?usp=sharing"
                            target="_blank">Unsupervised Project 1</a></h4>
                    <p>
                        This notebook is part of the M2 MLDS/AMSD program and focuses on unsupervised learning
                        techniques for analyzing and clustering high-dimensional data.
                        The project demonstrates the application of various unsupervised learning algorithms
                        <strong>(KMeans, Hierarchical Clustering, DBSCAN, )</strong>,
                        including clustering and dimensionality reduction <strong>(t-SNE, PCA, UMAP)</strong> to extract
                        meaningful
                        patterns and insights from complex NLP datasets.
                    </p>
                </div>
            </div>
            <hr>

            <!-- ################################ Unsupervised Project 2 ################################ -->
            <div class="project">
                <div><img src="assets/projects/proj_ul.png"></div>
                <div class="projectDescription">
                    <h4><a href="https://drive.google.com/file/d/1dQQaKYjG9htWB5mfyJoVveGlf4tJOHI7/view?usp=sharing"
                            target="_blank">Unsupervised Project</a></h4>
                    <p>The objective of this project is to use Unsupervised Classification methods to summarize the
                        variations
                        in energy consumption of 100 apartments, observed every 30 minutes over 91 consecutive days.
                        More
                        specifically, the aim here is to obtain a classification of the days, uniform for the
                        apartments. Such a
                        classification could be useful, for example, in the context of monitoring an electricity
                        network.
                    </p>
                </div>
            </div>
            <hr>

            <!-- ################################ Big Data ################################ -->
            <div class="project">
                <div><img src="assets/projects/big_data.png"></div>
                <div class="projectDescription">
                    <h4><a href="https://drive.google.com/file/d/1ZYHyC5YoVVkDoCaUJvjTSQlSjTUVUzMd/view?usp=sharing"
                            target="_blank">Big Data</a></h4>
                    <p>
                        This notebook is part of the M2 MLDS/AMSD program and focuses on exploring and analyzing
                        large-scale datasets using advanced machine learning and data science techniques.
                        The project demonstrates the application of big data methodologies, including data
                        preprocessing, feature engineering, and model building, to solve real-world problems.
                        It serves as a comprehensive guide for implementing scalable and efficient solutions in the
                        context of big data analytics.
                    </p>
                </div>
            </div>
            <hr>

        </section>
    </main>
    <script src="script.js"></script>
</body>

</html>